import torch
import torch.nn as nn
import torchvision.models as models

class ResNet18EncoderDecoderSkip(nn.Module):
    def __init__(self, num_classes=2):
        super(ResNet18EncoderDecoderSkip, self).__init__()
        
        # Load the ResNet18 model as the encoder
        self.encoder = models.resnet18(pretrained=True)
        
        # Modify the last layer of the encoder to output feature maps instead of a classification score
        self.encoder.fc = nn.Identity()
        
        # Define the decoder for image segmentation with skip connections
        self.decoder = nn.Sequential(
            nn.Conv2d(512, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, num_classes, kernel_size=1)
        )
        
        # Define skip connections from the encoder to the decoder
        self.skip1 = nn.Sequential(
            nn.Conv2d(256, 64, kernel_size=1),
            nn.BatchNorm2d(64),
        )
        self.skip2 = nn.Sequential(
            nn.Conv2d(128, 64, kernel_size=1),
            nn.BatchNorm2d(64),
        )
        self.skip3 = nn.Sequential(
            nn.Conv2d(64, 64, kernel_size=1),
            nn.BatchNorm2d(64),
        )
        
    def forward(self, x):
        # Pass the input through the encoder
        e1 = self.encoder.layer1(self.encoder.conv1(x))
        e2 = self.encoder.layer2(e1)
        e3 = self.encoder.layer3(e2)
        e4 = self.encoder.layer4(e3)
        
        # Pass the encoder output through the decoder with skip connections to get the mask
        d1 = self.decoder(e4)
        d1 += self.skip1(e3)
        d1 = nn.functional.relu(d1)
        d2 = nn.functional.interpolate(d1, scale_factor=2, mode='bilinear', align_corners=True)
        d2 = self.decoder(d2)
        d2 += self.skip2(e2)
        d2 = nn.functional.relu(d2)
        d3 = nn.functional.interpolate(d2, scale_factor=2, mode='bilinear', align_corners=True)
        d3 = self.decoder(d3)
        d3 += self.skip3(e1)
        d3 = nn.functional.relu(d3)
        d4 = nn.functional.interpolate(d3, scale_factor=2, mode='bilinear', align_corners=True)
        d4 = self.decoder(d4)
        
        # Apply a softmax activation to get the final mask probabilities
        mask = nn.functional.softmax(d4, dim=1)
        
        return mask



================================================================================================================================================

# Lightning

import torch.nn.functional as F
import pytorch_lightning as pl

class SegmentationModel(pl.LightningModule):
    def __init__(self, num_classes=2):
        super().__init__()
        self.resnet = models.resnet18(pretrained=True)
        self.encoder = nn.Sequential(*list(self.resnet.children())[:-3])

        self.middle = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(512),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(512)
        )

        self.decoder4 = DecoderBlock(768, 256)
        self.decoder3 = DecoderBlock(384, 128)
        self.decoder2 = DecoderBlock(192, 64)
        self.decoder1 = DecoderBlock(128, 64, use_skip_connection=False)

        self.classifier = nn.Conv2d(64, num_classes, kernel_size=1)

    def forward(self, x):
        x1 = self.encoder[0](x)
        x2 = self.encoder[1](x1)
        x3 = self.encoder[2](x2)
        x4 = self.encoder[3](x3)
        x5 = self.encoder[4](x4)
        x_middle = self.middle(x5)

        x_decoder4 = self.decoder4(x_middle, x4)
        x_decoder3 = self.decoder3(x_decoder4, x3)
        x_decoder2 = self.decoder2(x_decoder3, x2)
        x_decoder1 = self.decoder1(x_decoder2)

        mask = self.classifier(x_decoder1)
        return mask

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)
        return optimizer

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = F.cross_entropy(y_hat, y)
        self.log('train_loss', loss, on_step=False, on_epoch=True)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = F.cross_entropy(y_hat, y)
        self.log('val_loss', loss, on_step=False, on_epoch=True)

    def test_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = F.cross_entropy(y_hat, y)
        self.log('test_loss', loss, on_step=False, on_epoch=True)